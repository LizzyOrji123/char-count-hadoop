# Hadoop MapReduce Character Count ğŸ“Š

This project demonstrates how to build and run a simple **Hadoop MapReduce** application inside a Dockerized Hadoop environment on macOS. It counts the number of characters in a given text file and stores the output in HDFS.

## ğŸ§° Tools & Technologies

- Java
- Apache Hadoop (Single Node on Docker)
- VS Code
- GitHub
- macOS
- HDFS

## ğŸš€ How It Works

1. **Write Java Code**  
   The `CharacterCount.java` class defines the Mapper, Reducer, and Driver logic for processing text and counting character frequencies.

2. **Compile & Package**  
   The code is compiled and packaged into a JAR file using Hadoopâ€™s Java tools.

3. **Upload Input File**  
   The input text file is uploaded to the Hadoop Distributed File System (HDFS).

4. **Run MapReduce Job**  
   The JAR file is executed to process the input and output results to an HDFS directory.

5. **Result**  
   Output files are retrieved from HDFS, showcasing character frequencies.

## ğŸ”§ Setup & Usage

1. **Run Hadoop in Docker**  
   A single-node Hadoop container is launched from the terminal.

2. **Upload input file to HDFS**  
   ```bash
   hdfs dfs -mkdir /input
   hdfs dfs -put input.txt /input
Run the JAR file

```bash
Copy
Edit
hadoop jar charcount.jar CharacterCount /input /output
View Output

```bash
Copy
Edit
hdfs dfs -cat /output/part-r-00000

ğŸ“ Project Structure
```graphql
Copy
Edit
â”œâ”€â”€ CharacterCount.java
â”œâ”€â”€ charcount.jar
â”œâ”€â”€ input.txt
â”œâ”€â”€ output/            # Contains result files from HDFS
â”œâ”€â”€ Dockerfile         # (Optional) for custom Hadoop container
â””â”€â”€ README.md

âœ… Output Sample
```css
Copy
Edit
A   8
B   2
C   3
...








